[![CI status](https://github.com/Gowee/zhconv-rs/actions/workflows/main.yml/badge.svg)](https://github.com/Gowee/zhconv-rs/actions)
[![docs.rs](https://docs.rs/zhconv/badge.svg)](https://docs.rs/zhconv)
[![Crates.io](https://img.shields.io/crates/v/zhconv.svg)](https://crates.io/crates/zhconv)
[![PyPI version](https://img.shields.io/pypi/v/zhconv-rs)](https://pypi.org/project/zhconv-rs/)
[![NPM version](https://badge.fury.io/js/zhconv.svg)](https://www.npmjs.com/package/zhconv)

# zhconv-rs â€” ä¸­æ–‡ç®€ç¹åŠåœ°å€è©è½‰æ›

zhconv-rs converts Chinese between Traditional, Simplified and regional variants, using rulesets sourced from [MediaWiki](https://github.com/wikimedia/mediawiki)/Wikipedia and [OpenCC](https://github.com/BYVoid/OpenCC), which are merged, flattened and prebuilt into [Ahoâ€‘Corasick](https://en.wikipedia.org/wiki/Ahoâ€“Corasick_algorithm) automata for single-pass, linear-time conversions.

ğŸ”— **Web app (wasm):** <https://zhconv.pages.dev>

âš™ï¸ **Cli**: `cargo install zhconv` or download from [releases](https://github.com/Gowee/zhconv-rs/releases)

ğŸ¦€ **Rust crate**: `cargo add zhconv` (see [docs](https://docs.rs/zhconv/latest/zhconv/) for details)

```rust
use zhconv::{zhconv, Variant};
assert_eq!(zhconv("é›¾å¤±æ¥¼å°ï¼Œæœˆè¿·æ´¥æ¸¡", Variant::ZhTW), "éœ§å¤±æ¨“è‡ºï¼Œæœˆè¿·æ´¥æ¸¡");
assert_eq!(zhconv("é©›å¯„æ¢…èŠ±ï¼Œé­šå‚³å°ºç´ ", "zh-Hans".parse().unwrap()), "é©¿å¯„æ¢…èŠ±ï¼Œé±¼ä¼ å°ºç´ ");
```

ğŸ **Python package**: `pip install zhconv-rs` or `pip install zhconv-rs-opencc` (for additional OpenCC dictionaries)

```python
from zhconv_rs import zhconv
assert zhconv("å¤©å¹²ç‰©ç‡¥ å°å¿ƒç«çƒ›", "zh-tw") == "å¤©ä¹¾ç‰©ç‡¥ å°å¿ƒç«ç‡­"
```

<details>
 <summary>More usage</summary>

```python
assert zhconv("ã€Š-{zh-hans:ä¸‰ä¸ªç«æªæ‰‹;zh-hant:ä¸‰åŠå®¢;zh-tw:ä¸‰åŠå®¢}-ã€‹æ˜¯äºæ­·å±±å¤§Â·ä»²é¦¬çš„ä½œå“ã€‚", "zh-cn", mediawiki=True) == "ã€Šä¸‰ä¸ªç«æªæ‰‹ã€‹æ˜¯äºšå†å±±å¤§Â·ä»²é©¬çš„ä½œå“ã€‚"
assert zhconv("-{H|zh-cn:é›¾éƒ½å­¤å„¿;zh-tw:å­¤é››æ·š;zh-hk:è‹¦æµ·å­¤é››;zh-sg:é›¾éƒ½å­¤å„¿;zh-mo:è‹¦æµ·å­¤é››;}-ã€Šé›¾éƒ½å­¤å„¿ã€‹æ˜¯æŸ¥å°”æ–¯Â·ç‹„æ›´æ–¯çš„ä½œå“ã€‚", "zh-tw", True) == "ã€Šå­¤é››æ·šã€‹æ˜¯æŸ¥çˆ¾æ–¯Â·ç‹„æ›´æ–¯çš„ä½œå“ã€‚"

# Customize conversion tables:
from zhconv_rs import make_converter
assert make_converter(None, [("å¤©", "åœ°"), ("æ°´", "ç«")])("ç”˜è‚…å¤©æ°´") == "ç”˜è‚…åœ°ç«"

import io
convert = make_converter("zh-hans", io.StringIO("ä– å¤„\nç½¨ç•« æ©ç”»")) # or path to rule file
assert convert("ç§€å·è¥¿å»æ¹–å·è¿‘ å¹¾ä–æ¨“è‡ºç½¨ç•«é–“") == "ç§€å·è¥¿å»æ¹–å·è¿‘ å‡ å¤„æ¥¼å°æ©ç”»é—´"
```

</details>

<a href="https://deploy.workers.cloudflare.com/?url=https://github.com/gowee/zhconv-rs">
    <img src="https://deploy.workers.cloudflare.com/button" align="right" alt="Deploy to Cloudflare Workers">
</a>

ğŸ§© **API demo**: <https://zhconv.bamboo.workers.dev>

**Node.js package**: `npm install zhconv` or `yarn add zhconv`

**JS in browser**: <https://cdn.jsdelivr.net/npm/zhconv-web@latest>

<details>
 <summary>HTML snippet</summary>

```html
<script type="module">
    // Use ES module import syntax to import functionality from the module
    // that we have compiled.
    //
    // Note that the `default` import is an initialization function which
    // will "boot" the module and make it ready to use. Currently browsers
    // don't support natively imported WebAssembly as an ES module, but
    // eventually the manual initialization won't be required!
    import init, { zhconv } from 'https://cdn.jsdelivr.net/npm/zhconv-web@latest/zhconv.js'; // specify a version tag if in prod

    async function run() {
        await init();

        alert(zhconv(prompt("Text to convert to zh-hans:"), "zh-hans"));
    }

    run();
</script>
```


</details>

## Variants and conversion tables

Unlike OpenCC, whose dictionaries are bidirectional (e.g., `s2t`, `tw2s`), zhconv-rs follows MediaWikiâ€™s approach and provides one conversion table per target variant:

<details>
 <summary>zh-Hant, zh-Hans, zh-TW, zh-HK, zh-MO, zh-CN, zh-SG, zh-MY</summary>

| Target                                 | Tag       | Script  | Description                                   |
| -------------------------------------- | --------- | ------- | --------------------------------------------- |
| **S**implified **C**hinese / ç®€ä½“ä¸­æ–‡  | `zh-Hans` | SC / ç®€ | W/O substituing region-specific phrases.      |
| **T**raditional **C**hinese / ç¹é«”ä¸­æ–‡ | `zh-Hant` | TC / ç¹ | W/O substituing region-specific phrases.      |
| Chinese (Taiwan) / è‡ºç£æ­£é«”            | `zh-TW`   | TC / ç¹ | With Taiwan-specific phrases adapted.         |
| Chinese (Hong Kong) / é¦™æ¸¯ç¹é«”         | `zh-HK`   | TC / ç¹ | With Hong Kong-specific phrases adapted.      |
| Chinese (Macau) / æ¾³é—¨ç¹é«”             | `zh-MO`   | TC / ç¹ | Same as `zh-HK` for now.                      |
| Chinese (Mainland China) / å¤§é™†ç®€ä½“    | `zh-CN`   | SC / ç®€ | With mainland China-specific phrases adapted. |
| Chinese (Singapore) / æ–°åŠ å¡ç®€ä½“       | `zh-SG`   | SC / ç®€ | Same as `zh-CN` for now.                      |
| Chinese (Malaysia) / å¤§é©¬ç®€ä½“          | `zh-MY`   | SC / ç®€ | Same as `zh-CN` for now.                      |

*Note:*  `zh-TW` and `zh-HK` are derived from `zh-Hant`. `zh-CN` is derived from `zh-Hans`. Currently, `zh-MO` shares the same dictionary as `zh-HK`, and `zh-MY`/`zh-SG` share the same dictionary as `zh-CN`, unless additional rules are provided.
</details>

Chained dictionary groups from OpenCC are flattened and merged with the MediaWiki conversion table for each target variant, then compiled into an Aho-Corasick automaton at compile-time. After internal compression, the bundled conversion tables and automata occupy ~0.6 MiB (with MediWiki enabled only) or ~2.7 MiB (with both MediaWiki and OpenCC enabled).

## Performance

Even with all rulesets enabled, zhconv-rs remains faster than most alternatives. Check with `cargo bench compare --features bench,mediawiki,opencc`:

![Comparison with other crates, targetting zh-Hans](violin-to-hans.svg)
![Comparison with other crates, targetting zh-TW](violin-to-tw.svg)

Conversion runs in a single pass in `O(n+m)` linear time by default, where `n` is the length of the input text and `m` is the maximum length of source word in conversion tables, regardless of which rulesets are enabled. When converting wikitext containing MediaWiki conversion rules, the time complexity may degrade to `O(n*m)` in the worst case, if the corresponding function or flag is explicitly chosen.

On a typical modern PC, prebuilt converters load in a few milliseconds with default features (~2â€“5 ms). Enabling the optional opencc feature increases load time (typically 20â€“25 ms per target). Throughput generally ranges from 100â€“200 MB/s.

`cargo bench base --features bench` on `AMD EPYC 7B13` (GitPod) by v0.3:

<details>
<summary>Using conversion tables sourced from MediaWiki by default</summary>

```
load/zh2Hant            time:   [4.6368 ms 4.6862 ms 4.7595 ms]
load/zh2Hans            time:   [2.2670 ms 2.2891 ms 2.3138 ms]
load/zh2TW              time:   [4.7115 ms 4.7543 ms 4.8001 ms]
load/zh2HK              time:   [5.4438 ms 5.5474 ms 5.6573 ms]
load/zh2MO              time:   [4.9503 ms 4.9673 ms 4.9850 ms]
load/zh2CN              time:   [3.0809 ms 3.1046 ms 3.1323 ms]
load/zh2SG              time:   [3.0543 ms 3.0637 ms 3.0737 ms]
load/zh2MY              time:   [3.0514 ms 3.0640 ms 3.0787 ms]
zh2CN wikitext basic    time:   [385.95 Âµs 388.53 Âµs 391.39 Âµs]
zh2TW wikitext basic    time:   [393.70 Âµs 395.16 Âµs 396.89 Âµs]
zh2TW wikitext extended time:   [1.5105 ms 1.5186 ms 1.5271 ms]
zh2CN å¤©ä¹¾ç‰©ç‡¥          time:   [46.970 ns 47.312 ns 47.721 ns]
zh2TW data54k           time:   [200.72 Âµs 201.54 Âµs 202.41 Âµs]
zh2CN data54k           time:   [231.55 Âµs 232.86 Âµs 234.30 Âµs]
zh2Hant data689k        time:   [2.0330 ms 2.0513 ms 2.0745 ms]
zh2TW data689k          time:   [1.9710 ms 1.9790 ms 1.9881 ms]
zh2Hant data3185k       time:   [15.199 ms 15.260 ms 15.332 ms]
zh2TW data3185k         time:   [15.346 ms 15.464 ms 15.629 ms]
zh2TW data55m           time:   [329.54 ms 330.53 ms 331.58 ms]
is_hans data55k         time:   [404.73 Âµs 407.11 Âµs 409.59 Âµs]
infer_variant data55k   time:   [1.0468 ms 1.0515 ms 1.0570 ms]
is_hans data3185k       time:   [22.442 ms 22.589 ms 22.757 ms]
infer_variant data3185k time:   [60.205 ms 60.412 ms 60.627 ms]
```

</details>

<details>
<summary>Using conversion tables derived from OpenCC additionally (`--features opencc`)</summary>

```
load/zh2Hant            time:   [22.074 ms 22.338 ms 22.624 ms]
load/zh2Hans            time:   [2.7913 ms 2.8126 ms 2.8355 ms]
load/zh2TW              time:   [23.068 ms 23.286 ms 23.520 ms]
load/zh2HK              time:   [23.358 ms 23.630 ms 23.929 ms]
load/zh2MO              time:   [23.363 ms 23.627 ms 23.913 ms]
load/zh2CN              time:   [3.6778 ms 3.7222 ms 3.7722 ms]
load/zh2SG              time:   [3.6522 ms 3.6848 ms 3.7202 ms]
load/zh2MY              time:   [3.6642 ms 3.7079 ms 3.7545 ms]
zh2CN wikitext basic    time:   [396.17 Âµs 402.51 Âµs 409.36 Âµs]
zh2TW wikitext basic    time:   [442.16 Âµs 447.53 Âµs 453.27 Âµs]
zh2TW wikitext extended time:   [1.5795 ms 1.6007 ms 1.6233 ms]
zh2CN å¤©ä¹¾ç‰©ç‡¥          time:   [47.884 ns 48.878 ns 49.953 ns]
zh2TW data54k           time:   [255.25 Âµs 259.01 Âµs 262.92 Âµs]
zh2CN data54k           time:   [233.74 Âµs 236.99 Âµs 240.67 Âµs]
zh2Hant data689k        time:   [3.9696 ms 4.0005 ms 4.0327 ms]
zh2TW data689k          time:   [3.4593 ms 3.4896 ms 3.5203 ms]
zh2Hant data3185k       time:   [27.710 ms 27.955 ms 28.206 ms]
zh2TW data3185k         time:   [30.298 ms 30.858 ms 31.428 ms]
zh2TW data55m           time:   [500.95 ms 515.80 ms 531.34 ms]
is_hans data55k         time:   [461.22 Âµs 470.99 Âµs 481.20 Âµs]
infer_variant data55k   time:   [1.1669 ms 1.1759 ms 1.1852 ms]
is_hans data3185k       time:   [26.609 ms 26.964 ms 27.385 ms]
infer_variant data3185k time:   [74.878 ms 76.262 ms 77.818 ms]
```

</details>

## Limitations

### Accuracy

Rule-based converters cannot capture every possible linguistic nuance. Like most others, the implementation employs a leftmost-longest matching strategy (a.k.a forward maximum matching), prioritizing to the earliest and longest matches in the text. For example, if a ruleset contains both `å¹² â†’ å¹¹`, `å¤©å¹² â†’ å¤©å¹²`, and `å¤©å¹²ç‰©ç‡¥ â†’ å¤©ä¹¾ç‰©ç‡¥`, the converter will prefer the longer match `å¤©ä¹¾ç‰©ç‡¥`, since it appears earlier and spans more characters. This generally works well but may cause occasional mis-conversions.

### Wikitext support

The implementation supports most MediaWiki conversion syntax, while not fully compliant with the original MediaWiki implementation.

Since rebuilding automata dynamically is impractical, rules (e.g., `-{H|zh-hans:é¹¿|zh-hant:é©¬}-` in MediaWiki syntax) in text are extracted in a first pass, a temporary automaton is constructed, and the text is converted in a second pass. The time complexity may degrade to `O(n*m)` in the worst case, where `n` is the input text length and `m` is the maximum length of source words in dictionaries, which is equivalent to a brute-force approach.

## License

The library itself is licensed under MIT OR Apache-2.0, at the licenseeâ€™s option. **BUT** it may bundle:

- Conversion tables from MediaWiki (the default, gated by the feature `mediawiki`) which are licensed under GPL-2.0-or-later.
- Dictionaries from OpenCC (gated by the feature `opencc`)  licensed under Apache-2.0.

To make the library MIT-compatible, disable the default `mediawiki` feature and enable the `opencc` feature for prebuilt converters & conversion tables.

## Credits

Rulesets: [MediaWiki](https://github.com/wikimedia/mediawiki) and [OpenCC](https://github.com/BYVoid/OpenCC).

Fast double-array Aho-Corasick automata implementation in Rust: [daachorse](https://github.com/daac-tools/daachorse)

References & related implementations:

- <https://github.com/gumblex/zhconv> : Python implementation of `zhConver{ter,sion}.php`.
- <https://github.com/BYVoid/OpenCC/> : Widely adopted Chinese converter.
- <https://zh.wikipedia.org/wiki/Wikipedia:å­—è©è½‰æ›è™•ç†>
- <https://zh.wikipedia.org/wiki/Help:é«˜çº§å­—è¯è½¬æ¢è¯­æ³•>
- <https://github.com/wikimedia/mediawiki/blob/master/includes/language/LanguageConverter.php>
