[![CI status](https://github.com/Gowee/zhconv-rs/actions/workflows/main.yml/badge.svg)](https://github.com/Gowee/zhconv-rs/actions)
[![docs.rs](https://docs.rs/zhconv/badge.svg)](https://docs.rs/zhconv)
[![Crates.io](https://img.shields.io/crates/v/zhconv.svg)](https://crates.io/crates/zhconv)
[![PyPI version](https://img.shields.io/pypi/v/zhconv-rs)](https://pypi.org/project/zhconv-rs/)
[![NPM version](https://badge.fury.io/js/zhconv.svg)](https://www.npmjs.com/package/zhconv)

# zhconv-rs ä¸­æ–‡ç®€ç¹åŠåœ°å€è©è½‰æ›

zhconv-rs converts Chinese text among traditional/simplified scripts or regional variants (e.g. `zh-TW <-> zh-CN <-> zh-HK <-> zh-Hans <-> zh-Hant`), backed by rulesets from MediaWiki/Wikipedia and OpenCC.

It leverages the [Aho-Corasick](https://github.com/daac-tools/daachorse) algorithm for linear time complexity with respect to the length of input text and conversion rules (`O(n+m)`), processing dozens of MiBs text per second.

ğŸ”— **Web app: https://zhconv.pages.dev** (powered by WASM)

âš™ï¸ **Cli**: `cargo install zhconv-cli` or check [releases](https://github.com/Gowee/zhconv-rs/releases).

ğŸ¦€ **Rust crate**: `cargo add zhconv` (check [docs](https://docs.rs/zhconv/latest/zhconv/) for examples)

ğŸ **Python package w/ wheels via PyO3**: `pip install zhconv-rs` or `pip install zhconv-rs-opencc` (with rulesets from OpenCC)

<details open>
 <summary>Python snippet</summary>

```python
# > pip install zhconv_rs
# Convert with builtin rulesets:
from zhconv_rs import zhconv
assert zhconv("å¤©å¹²ç‰©ç‡¥ å°å¿ƒç«çƒ›", "zh-tw") == "å¤©ä¹¾ç‰©ç‡¥ å°å¿ƒç«ç‡­"
assert zhconv("éœ§å¤±æ¨“è‡ºï¼Œæœˆè¿·æ´¥æ¸¡", "zh-hans") == "é›¾å¤±æ¥¼å°ï¼Œæœˆè¿·æ´¥æ¸¡"
assert zhconv("ã€Š-{zh-hans:ä¸‰ä¸ªç«æªæ‰‹;zh-hant:ä¸‰åŠå®¢;zh-tw:ä¸‰åŠå®¢}-ã€‹æ˜¯äºæ­·å±±å¤§Â·ä»²é¦¬çš„ä½œå“ã€‚", "zh-cn", mediawiki=True) == "ã€Šä¸‰ä¸ªç«æªæ‰‹ã€‹æ˜¯äºšå†å±±å¤§Â·ä»²é©¬çš„ä½œå“ã€‚"
assert zhconv("-{H|zh-cn:é›¾éƒ½å­¤å„¿;zh-tw:å­¤é››æ·š;zh-hk:è‹¦æµ·å­¤é››;zh-sg:é›¾éƒ½å­¤å„¿;zh-mo:è‹¦æµ·å­¤é››;}-ã€Šé›¾éƒ½å­¤å„¿ã€‹æ˜¯æŸ¥å°”æ–¯Â·ç‹„æ›´æ–¯çš„ä½œå“ã€‚", "zh-tw", True) == "ã€Šå­¤é››æ·šã€‹æ˜¯æŸ¥çˆ¾æ–¯Â·ç‹„æ›´æ–¯çš„ä½œå“ã€‚"

# Convert with custom rules:
from zhconv_rs import make_converter
assert make_converter(None, [("å¤©", "åœ°"), ("æ°´", "ç«")])("ç”˜è‚…å¤©æ°´") == "ç”˜è‚…åœ°ç«"

import io
convert = make_converter("zh-hans", io.StringIO("ä– å¤„\nç½¨ç•« æ©ç”»")) # or path to rule file
assert convert("ç§€å·è¥¿å»æ¹–å·è¿‘ å¹¾ä–æ¨“è‡ºç½¨ç•«é–“") == "ç§€å·è¥¿å»æ¹–å·è¿‘ å‡ å¤„æ¥¼å°æ©ç”»é—´"
```

</details>

**JS (Webpack)**: `npm install zhconv` or `yarn add zhconv` (WASM, [instructions](https://rustwasm.github.io/wasm-pack/book/tutorials/npm-browser-packages/using-your-library.html))

**JS in browser**: https://cdn.jsdelivr.net/npm/zhconv-web@latest (WASM)

<details>
 <summary>HTML snippet</summary>

```html
<script type="module">
    // Use ES module import syntax to import functionality from the module
    // that we have compiled.
    //
    // Note that the `default` import is an initialization function which
    // will "boot" the module and make it ready to use. Currently browsers
    // don't support natively imported WebAssembly as an ES module, but
    // eventually the manual initialization won't be required!
    import init, { zhconv } from 'https://cdn.jsdelivr.net/npm/zhconv-web@latest/zhconv.js'; // specify a version tag if in prod

    async function run() {
        await init();

        alert(zhconv(prompt("Text to convert to zh-hans:"), "zh-hans"));
    }

    run();
</script>
```

</details>

## Supported variants

<details>
 <summary>zh-Hant, zh-Hans, zh-TW, zh-HK, zh-MO, zh-CN, zh-SG, zh-MY</summary>

| Target                                 | Tag       | Script  | Description                                   |
| -------------------------------------- | --------- | ------- | --------------------------------------------- |
| **S**implified **C**hinese / ç®€ä½“ä¸­æ–‡  | `zh-Hans` | SC / ç®€ | W/O substituing region-specific phrases.      |
| **T**raditional **C**hinese / ç¹é«”ä¸­æ–‡ | `zh-Hant` | TC / ç¹ | W/O substituing region-specific phrases.      |
| Chinese (Taiwan) / è‡ºç£æ­£é«”            | `zh-TW`   | TC / ç¹ | With Taiwan-specific phrases adapted.         |
| Chinese (Hong Kong) / é¦™æ¸¯ç¹é«”         | `zh-HK`   | TC / ç¹ | With Hong Kong-specific phrases adapted.      |
| Chinese (Macau) / æ¾³é—¨ç¹é«”             | `zh-MO`   | TC / ç¹ | Same as `zh-HK` for now.                      |
| Chinese (Mainland China) / å¤§é™†ç®€ä½“    | `zh-CN`   | SC / ç®€ | With mainland China-specific phrases adapted. |
| Chinese (Singapore) / æ–°åŠ å¡ç®€ä½“       | `zh-SG`   | SC / ç®€ | Same as `zh-CN` for now.                      |
| Chinese (Malaysia) / å¤§é©¬ç®€ä½“          | `zh-MY`   | SC / ç®€ | Same as `zh-CN` for now.                      |

*Note:*  `zh-TW` and `zh-HK` are based on `zh-Hant`. `zh-CN` are based on `zh-Hans`. Currently, `zh-MO` shares the same rulesets with `zh-HK` unless additional rules are manually configured; `zh-MY` and `zh-SG` shares the same rulesets with `zh-CN` unless additional rules are manually configured. 
</details>

## Performance

`cargo bench` on `AMD EPYC 7B13` (GitPod) by v0.3:

<details>
<summary>w/ default features</summary>

```
load/zh2Hant            time:   [4.6368 ms 4.6862 ms 4.7595 ms]
load/zh2Hans            time:   [2.2670 ms 2.2891 ms 2.3138 ms]
load/zh2TW              time:   [4.7115 ms 4.7543 ms 4.8001 ms]
load/zh2HK              time:   [5.4438 ms 5.5474 ms 5.6573 ms]
load/zh2MO              time:   [4.9503 ms 4.9673 ms 4.9850 ms]
load/zh2CN              time:   [3.0809 ms 3.1046 ms 3.1323 ms]
load/zh2SG              time:   [3.0543 ms 3.0637 ms 3.0737 ms]
load/zh2MY              time:   [3.0514 ms 3.0640 ms 3.0787 ms]
zh2CN wikitext basic    time:   [385.95 Âµs 388.53 Âµs 391.39 Âµs]
zh2TW wikitext basic    time:   [393.70 Âµs 395.16 Âµs 396.89 Âµs]
zh2TW wikitext extended time:   [1.5105 ms 1.5186 ms 1.5271 ms]
zh2CN å¤©ä¹¾ç‰©ç‡¥          time:   [46.970 ns 47.312 ns 47.721 ns]
zh2TW data54k           time:   [200.72 Âµs 201.54 Âµs 202.41 Âµs]
zh2CN data54k           time:   [231.55 Âµs 232.86 Âµs 234.30 Âµs]
zh2Hant data689k        time:   [2.0330 ms 2.0513 ms 2.0745 ms]
zh2TW data689k          time:   [1.9710 ms 1.9790 ms 1.9881 ms]
zh2Hant data3185k       time:   [15.199 ms 15.260 ms 15.332 ms]
zh2TW data3185k         time:   [15.346 ms 15.464 ms 15.629 ms]
zh2TW data55m           time:   [329.54 ms 330.53 ms 331.58 ms]
is_hans data55k         time:   [404.73 Âµs 407.11 Âµs 409.59 Âµs]
infer_variant data55k   time:   [1.0468 ms 1.0515 ms 1.0570 ms]
is_hans data3185k       time:   [22.442 ms 22.589 ms 22.757 ms]
infer_variant data3185k time:   [60.205 ms 60.412 ms 60.627 ms]
``` 
</details>

<details>
<summary>w/ the additional non-default `opencc` feature</summary>

```
load/zh2Hant            time:   [22.074 ms 22.338 ms 22.624 ms]
load/zh2Hans            time:   [2.7913 ms 2.8126 ms 2.8355 ms]
load/zh2TW              time:   [23.068 ms 23.286 ms 23.520 ms]
load/zh2HK              time:   [23.358 ms 23.630 ms 23.929 ms]
load/zh2MO              time:   [23.363 ms 23.627 ms 23.913 ms]
load/zh2CN              time:   [3.6778 ms 3.7222 ms 3.7722 ms]
load/zh2SG              time:   [3.6522 ms 3.6848 ms 3.7202 ms]
load/zh2MY              time:   [3.6642 ms 3.7079 ms 3.7545 ms]
zh2CN wikitext basic    time:   [396.17 Âµs 402.51 Âµs 409.36 Âµs]
zh2TW wikitext basic    time:   [442.16 Âµs 447.53 Âµs 453.27 Âµs]
zh2TW wikitext extended time:   [1.5795 ms 1.6007 ms 1.6233 ms]
zh2CN å¤©ä¹¾ç‰©ç‡¥          time:   [47.884 ns 48.878 ns 49.953 ns]
zh2TW data54k           time:   [255.25 Âµs 259.01 Âµs 262.92 Âµs]
zh2CN data54k           time:   [233.74 Âµs 236.99 Âµs 240.67 Âµs]
zh2Hant data689k        time:   [3.9696 ms 4.0005 ms 4.0327 ms]
zh2TW data689k          time:   [3.4593 ms 3.4896 ms 3.5203 ms]
zh2Hant data3185k       time:   [27.710 ms 27.955 ms 28.206 ms]
zh2TW data3185k         time:   [30.298 ms 30.858 ms 31.428 ms]
zh2TW data55m           time:   [500.95 ms 515.80 ms 531.34 ms]
is_hans data55k         time:   [461.22 Âµs 470.99 Âµs 481.20 Âµs]
infer_variant data55k   time:   [1.1669 ms 1.1759 ms 1.1852 ms]
is_hans data3185k       time:   [26.609 ms 26.964 ms 27.385 ms]
infer_variant data3185k time:   [74.878 ms 76.262 ms 77.818 ms]
```

</details>

By default, only rulesets from MediaWiki are used. `opencc` feature can be enabled with `zhconv = { version = "...", features = [ "opencc" ] }`. 
But be noted that, other than performance decrease, it accounts for at least several MiBs in build output.

<!--
## Differences with other converters
* `ZhConver{sion,ter}.php` of MediaWiki: zhconv-rs just takes conversion tables listed in [`ZhConversion.php`](https://github.com/wikimedia/mediawiki/blob/master/includes/languages/data/ZhConversion.php#L14). MediaWiki relies on the inefficient PHP built-in function [`strtr`](https://github.com/php/php-src/blob/217fd932fa57d746ea4786b01d49321199a2f3d5/ext/standard/string.c#L2974). Under the basic mode, zhconv-rs guarantees linear time complexity (`T = O(n+m)` instead of `O(nm)`) and single-pass scanning of input text. Optionally, zhconv-rs supports the same conversion rule syntax with MediaWiki.
* OpenCC: The [conversion rulesets](https://github.com/BYVoid/OpenCC/tree/master/data/dictionary) of OpenCC is independent of MediaWiki. The core [conversion implementation](https://github.dev/BYVoid/OpenCC/blob/21995f5ea058441423aaff3ee89b0a5d4747674c/src/Conversion.cpp#L27) of OpenCC is kinda similar to the aforementioned `strtr`. However, OpenCC supports pre-segmentation and maintains multiple rulesets which are applied successively. By contrast, the Aho-Corasick-powered zhconv-rs merges rulesets from MediaWiki and OpenCC in compile time and converts text in single-pass linear time, resulting in much more efficiency. Though, conversion results may differ in some cases.
## Comparisions with other tools
- OpenCC: Dict::MatchPrefix (iterating from maxlen to minlen character by character to match) [https://github.dev/BYVoid/OpenCC/blob/21995f5ea058441423aaff3ee89b0a5d4747674c/src/Dict.cpp#L25](MatchPrefix), [segments converter](https://github.dev/BYVoid/OpenCC/blob/21995f5ea058441423aaff3ee89b0a5d4747674c/src/Conversion.cpp#L27) [segmentizer](https://github.dev/BYVoid/OpenCC/blob/21995f5ea058441423aaff3ee89b0a5d4747674c/src/MaxMatchSegmentation.cpp#L34)
- zhConversion.php: strtr (iterating from maxlen to minlen for every known key length to match) [https://github.dev/php/php-src/blob/217fd932fa57d746ea4786b01d49321199a2f3d5/ext/standard/string.c#L2974]
- zhconv-rs regex-based automaton
-->

## Limitations

### Accuracy

A rule-based converter cannot capture every possible linguistic nuance, resulting in limited accuracy. Besides, the converter employs a leftmost-longest matching strategy, prioritizing to the earliest and longest matches in the text. For instance, if a ruleset includes both `å¹² -> å¹¹` and `å¤©å¹²ç‰©ç‡¥ -> å¤©ä¹¾ç‰©ç‡¥`, the converter would prioritize `å¤©ä¹¾ç‰©ç‡¥` because `å¤©å¹²ç‰©ç‡¥` gets matched earlier compared to `å¹²` at a later position. This approach generally produces accurate results but may occasionally lead to incorrect conversions.

### Wikitext support

While the implementation supports most MediaWiki conversion rules, it is not fully compliant with the original MediaWiki implementation.

For wikitext inputs containing global conversion rules (e.g., `-{H|zh-hans:é¹¿|zh-hant:é©¬}-` in MediaWiki syntax), the implementation's time complexity may degrade to `O(n*m)` in the worst case, where `n` is the input text length and `m` is the maximum length of source words in the ruleset. This is equivalent to a brute-force approach.

## Credits

Rulesets/Dictionaries: [MediaWiki](https://github.com/wikimedia/mediawiki) and [OpenCC](https://github.com/BYVoid/OpenCC).

References:
- https://github.com/gumblex/zhconv : Python implementation of `zhConver{ter,sion}.php`.
- https://github.com/BYVoid/OpenCC/ : Widely adopted Chinese converter.
- https://zh.wikipedia.org/wiki/Wikipedia:å­—è©è½‰æ›è™•ç†
- https://zh.wikipedia.org/wiki/Help:é«˜çº§å­—è¯è½¬æ¢è¯­æ³•
- https://github.com/wikimedia/mediawiki/blob/master/includes/language/LanguageConverter.php
<!--- https://www.hankcs.com/nlp/simplified-traditional-chinese-conversion.html-->
